# -*- coding: utf-8 -*-
"""Ap

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p-yk0_MqHBaNFBBHTm_SWuxt8QiyJwQq
"""

# -*- coding: utf-8 -*-
"""Project X(CN AP) - V13.0 Active Edition
此版本为最终整合版，包含：
1. 多品种数据加载 (Apple + Corn + Egg)
2. 自动化天气数据获取 (Open-Meteo)
3. 季节性 + 宏观 + 天气 多因子特征工程
4. 概率阈值激活交易 (Probability Threshold > 0.52)
"""

# ==============================================================================
# Block 1: 核心库与工具函数 (Core Libraries & Helpers)
# ==============================================================================
import numpy as np
import pandas as pd
import lightgbm as lgb
import warnings
import requests
import io
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from scipy.stats.mstats import winsorize

# Suppress Warnings
warnings.filterwarnings('ignore')

print("Block 1: Libraries Loaded.")

def process_continuous_contract(df, symbol_prefix, date_col, symbol_col, open_interest_col, close_col):
    """处理主力连续合约"""
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])
    # 找主力
    idx = df.groupby(date_col)[open_interest_col].idxmax()
    main_df = df.loc[idx].sort_values(date_col).reset_index(drop=True)
    # 简单后复权
    main_df[f'{symbol_prefix}_close_adj'] = main_df[close_col]

    rename_dict = {date_col: 'date', close_col: f'{symbol_prefix}_close'}
    return main_df.rename(columns=rename_dict)

def load_data_from_upload(uploaded_file_map):
    """从上传加载数据"""
    if not uploaded_file_map: return None
    file_name = list(uploaded_file_map.keys())[0]
    print(f"Loading '{file_name}'...")
    try:
        if file_name.endswith('.xlsx'):
            return pd.read_excel(io.BytesIO(uploaded_file_map[file_name]))
        else:
            try:
                return pd.read_csv(io.BytesIO(uploaded_file_map[file_name]), encoding='utf-8')
            except:
                return pd.read_csv(io.BytesIO(uploaded_file_map[file_name]), encoding='gbk')
    except Exception as e:
        print(f"Error: {e}")
        return None


# ==============================================================================
# Block 2: 数据上传 (Data Loading)
# ==============================================================================
print("\nBlock 2: Uploading Files (Apple, Corn, Egg)...")

print("\n--- [1/3] Upload 'apple_futures_main_continuous_czce.csv' ---")
df_apple_raw = load_data_from_upload(files.upload())

print("\n--- [2/3] Upload 'All_Corn_Futures_Data_Cleaned.xlsx' ---")
df_corn_raw = load_data_from_upload(files.upload())

print("\n--- [3/3] Upload 'All_Egg_Futures_Data_Cleaned.xlsx' ---")
df_egg_raw = load_data_from_upload(files.upload())

if df_apple_raw is None or df_corn_raw is None or df_egg_raw is None:
    print("[WARNING] Files missing! Code may fail later.")


# ==============================================================================
# Block 3: 数据清洗 (Data Cleaning)
# ==============================================================================
print("\nBlock 3: Processing Data...")
try:
    # 1. Process Apple
    df_apple = process_continuous_contract(df_apple_raw, 'AP', 'date', 'symbol', 'open_interest', 'close')
    # 2. Process Corn
    df_corn = process_continuous_contract(df_corn_raw, 'C', 'Trade_Date', 'Contract', 'Open_Interest', 'Close')
    # 3. Process Egg
    df_egg = process_continuous_contract(df_egg_raw, 'JD', 'Trade_Date', 'Contract', 'Open_Interest', 'Close')

    # Merge
    df_m = pd.merge(df_apple, df_corn[['date', 'C_close_adj']], on='date', how='inner')
    df_model_ready = pd.merge(df_m, df_egg[['date', 'JD_close_adj']], on='date', how='inner')

    # Calc Return for Volatility
    df_model_ready['AP_return_1d'] = df_model_ready['AP_close_adj'].pct_change(1)

    print(f"Merged Data Shape: {df_model_ready.shape}")

except Exception as e:
    print(f"[ERROR] Block 3 Failed: {e}")


# ==============================================================================
# Block 4: 天气数据 (Weather API)
# ==============================================================================
print("\nBlock 4: Fetching Weather Data...")
locs = {
    "luochuan": {"latitude": 35.76, "longitude": 109.43},
    "yantai": {"latitude": 37.53, "longitude": 121.39},
    "tianshui": {"latitude": 34.58, "longitude": 105.72},
    "lingbao": {"latitude": 34.51, "longitude": 110.88}
}
weather_data_raw_dict = {}
url = "https://archive-api.open-meteo.com/v1/archive"
params = {"start_date": "2017-01-01", "end_date": "2025-10-25",
          "daily": ["temperature_2m_min", "temperature_2m_max"], "timezone": "Asia/Shanghai"}

try:
    for n, c in locs.items():
        p = params.copy(); p.update(c)
        res = requests.get(url, params=p).json()
        weather_data_raw_dict[n] = pd.DataFrame({
            "date": pd.to_datetime(res['daily']['time']),
            "temp_min": res['daily']['temperature_2m_min'],
            "temp_max": res['daily']['temperature_2m_max']
        })
    print("Weather data fetched successfully.")
except Exception as e:
    print(f"[ERROR] Weather fetch failed: {e}")


# ==============================================================================
# Block 5: V13.0 特征工程与激活回测 (Active Modeling)
# ==============================================================================
print("\nBlock 5: Starting V13.0 Active Modeling...")

# --- 1. Labeling (宽松版) ---
def apply_flexible_labeling(df, lookahead=15, profit_threshold=0.02):
    """未来15天内只要触及 +2% 就算好机会 (1)，否则为 (0)"""
    labels = []
    prices = df['AP_close_adj'].values
    for i in range(len(prices) - lookahead):
        future_high = np.max(prices[i+1 : i+1+lookahead])
        curr = prices[i]
        if (future_high / curr - 1) > profit_threshold:
            labels.append(1)
        else:
            labels.append(0)
    labels.extend([np.nan] * lookahead)
    return np.array(labels)

try:
    df_rob = df_model_ready.copy()

    # --- 特征构建 ---
    # [A] 自身技术面
    df_rob['AP_return_10d'] = df_rob['AP_close_adj'].pct_change(10)
    df_rob['AP_vol_20d'] = df_rob['AP_return_1d'].rolling(20).std()

    # [B] 宏观联动 (玉米/鸡蛋)
    df_rob['C_return_10d'] = df_rob['C_close_adj'].pct_change(10)
    df_rob['JD_return_10d'] = df_rob['JD_close_adj'].pct_change(10)
    df_rob['AP_C_Ratio_Change'] = (df_rob['AP_close_adj'] / df_rob['C_close_adj']).pct_change(10)

    # [C] 季节性
    df_rob['month'] = df_rob['date'].dt.month
    df_rob['sin_month'] = np.sin(2 * np.pi * df_rob['month'] / 12)

    # [D] 天气聚合
    gdd_cols = []
    for name, df_w in weather_data_raw_dict.items():
        t_df = df_w.copy().set_index('date')
        # GDD: 有效积温
        t_df[f'gdd_{name}'] = (((t_df['temp_max'] + t_df['temp_min']) / 2) - 10).clip(lower=0)
        t_df[f'cum_gdd_{name}'] = t_df.groupby(t_df.index.year)[f'gdd_{name}'].cumsum()

        df_rob = pd.merge(df_rob, t_df[[f'cum_gdd_{name}']].reset_index(), on='date', how='inner')
        gdd_cols.append(f'cum_gdd_{name}')

    df_rob['national_gdd'] = df_rob[gdd_cols].mean(axis=1)

    # --- 特征列表 ---
    FEATURES = [
        'AP_return_10d', 'AP_vol_20d', 'national_gdd',
        'C_return_10d', 'JD_return_10d', 'AP_C_Ratio_Change', 'sin_month'
    ]

    # --- 数据准备 ---
    df_rob['target'] = apply_flexible_labeling(df_rob, lookahead=15, profit_threshold=0.02)
    df_rob = df_rob.dropna(subset=FEATURES + ['target'])

    # 缩尾处理 (防止极端值)
    for col in ['AP_return_10d', 'AP_vol_20d', 'C_return_10d', 'national_gdd']:
        df_rob[col] = winsorize(df_rob[col], limits=[0.01, 0.01])

    # --- 回测引擎 (概率激活版) ---
    trades = []
    init_size = 1000
    step = 252

    df_rob = df_rob.sort_values('date').reset_index(drop=True)
    print(f"Starting Walk-Forward Validation on {len(df_rob)} rows...")

    for i in range(init_size, len(df_rob) - step, step):
        train = df_rob.iloc[:i-16] # Buffer
        test = df_rob.iloc[i : i+step].copy()

        # 参数调整：稍微激进一点，reg_lambda 降为 2.0
        model = lgb.LGBMClassifier(
            n_estimators=150, max_depth=4, learning_rate=0.04,
            reg_lambda=2.0, colsample_bytree=0.8, random_state=42, verbosity=-1
        )

        X_tr = train[FEATURES].shift(1).dropna()
        y_tr = train.loc[X_tr.index, 'target']

        if len(np.unique(y_tr)) < 2: continue
        model.fit(X_tr, y_tr)

        # 预测概率
        X_te = test[FEATURES].shift(1).fillna(0)
        test['prob'] = model.predict_proba(X_te)[:, 1]

        # --- 交易执行 ---
        in_pos, entry_p, days = False, 0, 0

        for idx, row in test.iterrows():
            if in_pos:
                days += 1
                ret = (row['AP_close_adj'] / entry_p) - 1
                # 止盈 6%, 止损 3%, 或持仓 15天
                if ret <= -0.03 or ret >= 0.06 or days >= 15:
                    trades.append(ret)
                    in_pos = False
            else:
                # [关键] 概率阈值 > 0.52 即开仓
                if row['prob'] > 0.52:
                    in_pos = True
                    entry_p = row['AP_close_adj']
                    days = 0

    # --- 结果展示 ---
    if trades:
        tr_df = pd.DataFrame({'ret': trades})
        sharpe = (tr_df['ret'].mean() / tr_df['ret'].std()) * np.sqrt(252/15)
        cum_ret = (1 + tr_df['ret']).cumprod().iloc[-1] - 1

        print("\n" + "="*40)
        print("V13.0 ACTIVE RESULTS")
        print("="*40)
        print(f"Total Trades: {len(trades)}")
        print(f"Sharpe Ratio: {sharpe:.4f}")
        print(f"Total Return: {cum_ret*100:.2f}%")

        plt.figure(figsize=(10,5))
        (1 + tr_df['ret']).cumprod().plot()
        plt.title('V13.0 Cumulative Return')
        plt.grid(True)
        plt.show()
    else:
        print("No trades generated. Try lowering threshold to 0.51 or 0.50.")

except Exception as e:
    print(f"\n[CRITICAL ERROR] {e}")
    import traceback
    traceback.print_exc()